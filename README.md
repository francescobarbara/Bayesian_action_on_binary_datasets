
Imagine you have a dataset M with binary entries, you can identify a row r only by repeatedly asking whether row r has a 0 or a 1 at some i-th place. A first approach, which is the optimal approach if we assume that rows are independent of each other, is that of picking each time the column where the number of 0s and 1s is about the same (see greed_vec in the script). Since the matrix M is fixed and you ideally want to carry out this "guessing process" several times, you want to find a 'decision tree of the columns to pick' which minimizes the number picks until the row is uniquely identified (we assume r is uniformly distributed on (1,nrow(M)). For the implementation see (optimal_tree in the script) Now, imagine you are playing a game where the first who guesses the row correctly wins. Assume your opponent is playing under the 'independence assumption' and hence using the first strategy (greed_vec) as their decision tree. Through a number of educated simulations we can identify strategies (i.e. decision trees) which outperform your opponent as often as 80% of the time (depending on the matrix obviously). The idea for this project came to my mind when I was trying to find an optimal strategy for playing the popular board game 'Guess the character'. It is surprising how, even for these small datasets (generally 30x20) you can have a substantial hedge by adopting my strategy.
